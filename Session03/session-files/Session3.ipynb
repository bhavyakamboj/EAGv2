{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.50.1-py3-none-any.whl.metadata (46 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai)\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from google-genai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting requests<3.0.0,>=2.28.1 (from google-genai)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.11.0 (from google-genai)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading google_genai-1.50.1-py3-none-any.whl (257 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: websockets, urllib3, typing-extensions, tenacity, sniffio, python-dotenv, pyasn1, idna, h11, charset_normalizer, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, httpcore, anyio, pydantic, httpx, google-auth, google-genai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [google-genai][0m [google-genai]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 cachetools-6.2.2 certifi-2025.11.12 charset_normalizer-3.4.4 google-auth-2.43.0 google-genai-1.50.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.4 pydantic-core-2.41.5 python-dotenv-1.2.1 requests-2.32.5 rsa-4.9.1 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Let $F_n$ denote the $n$-th Fibonacci number, where $F_1 = 1$, $F_2 = 1$, and $F_n = F_{n-1} + F_{n-2}$ for $n \\geq 3$.\n",
      "We are asked to calculate the sum of exponentials of the first 3 Fibonacci numbers. Let's denote the sum as $S$. The first 3 Fibonacci numbers are $F_1 = 1$, $F_2 = 1$, and $F_3 = 2$.\n",
      "We need to calculate the sum of exponentials of these Fibonacci numbers, i.e., $S = e^{F_1} + e^{F_2} + e^{F_3}$.\n",
      "Substituting the values of the first three Fibonacci numbers, we have\n",
      "$S = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
      "Using the approximation $e \\approx 2.71828$, we can estimate the sum as\n",
      "$S = 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.389056 \\approx 12.825616$.\n",
      "Therefore, the sum of exponentials of the first 3 Fibonacci numbers is $2e + e^2$.\n",
      "\n",
      "The sum is\n",
      "$$S = e^{F_1} + e^{F_2} + e^{F_3} = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2 = e(2+e).$$\n",
      "Numerically, $S = 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.389056 \\approx 12.825616$.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{e^2+2e}$\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "print(api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Calculate the sum of exponentials of first 3 Fibonacci numbers\",\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 Fibonacci numbers are $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "We want to calculate the sum of exponentials of these first 3 Fibonacci numbers.\n",
    "Let the sum be $S = e^{F_1} + e^{F_2} + e^{F_3}$.\n",
    "We have $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "Then $S = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
    "We can approximate the value of $e$ as $2.71828$.\n",
    "So, $S = 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "We are asked to calculate the sum of exponentials of the first 3 Fibonacci numbers.\n",
    "Let the first 3 Fibonacci numbers be $F_1$, $F_2$, and $F_3$.\n",
    "Then $F_1 = 1$, $F_2 = 1$, $F_3 = 2$.\n",
    "The sum of exponentials of these numbers is $e^{F_1} + e^{F_2} + e^{F_3} = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2 = e(2+e)$.\n",
    "If we use the approximation $e \\approx 2.71828$, then\n",
    "$2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "The exact value is $2e + e^2$.\n",
    "\n",
    "Final Answer: The final answer is $\\boxed{2e+e^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION_CALL: strings_to_chars_to_int|TSAI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def strings_to_chars_to_int(string):\n",
    "    return [ord(char) for char in string]\n",
    "\n",
    "def int_list_to_exponential_sum(int_list):\n",
    "    int_list = eval(int_list)\n",
    "    return sum(math.exp(i) for i in int_list)\n",
    "\n",
    "def fibonacci_numbers(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    fib_sequence = [0, 1]\n",
    "    for _ in range(2, n):\n",
    "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
    "    return fib_sequence[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FUNCTION_CALL: strings_to_chars_to_int|TSAI'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = response.text.strip()\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FUNCTION_CALL', ' strings_to_chars_to_int|TSAI')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, function_info = response_text.split(\":\", 1)\n",
    "_, function_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('strings_to_chars_to_int', 'TSAI')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "\n",
    "func_name, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_caller(func_name, params):\n",
    "    \"\"\"Simple function caller that maps function names to actual functions\"\"\"\n",
    "    function_map = {\n",
    "        \"strings_to_chars_to_int\": strings_to_chars_to_int,\n",
    "        \"int_list_to_exponential_sum\": int_list_to_exponential_sum,\n",
    "        \"fibonacci_numbers\": fibonacci_numbers\n",
    "    }\n",
    "    \n",
    "    if func_name in function_map:\n",
    "        return function_map[func_name](params)\n",
    "    else:\n",
    "        return f\"Function {func_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_result = function_caller(func_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION_CALL: int_list_to_exponential_sum|[84, 83, 65, 73]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the following:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1379916178780975e+36"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = response.text.strip()\n",
    "_, function_info = response_text.split(\":\", 1)\n",
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "iteration_result = function_caller(func_name, params)\n",
    "iteration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_ANSWER: [4.1379916178780975e+36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called strings_to_chars_to_int with TSAI parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "iteration_2 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\\n\\n{iteration_2}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "LLM Response: FUNCTION_CALL: strings_to_chars_to_int|TSAI\n",
      "  Result: [84, 83, 65, 73]\n",
      "\n",
      "--- Iteration 2 ---\n",
      "LLM Response: FUNCTION_CALL: int_list_to_exponential_sum|[84, 83, 65, 73]\n",
      "  Result: 4.1379916178780975e+36\n",
      "\n",
      "--- Iteration 3 ---\n",
      "LLM Response: FINAL_ANSWER: [4.1379916178780975e+36]\n",
      "\n",
      "=== Agent Execution Complete ===\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "iteration_response = []\n",
    "\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(iteration_response)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    iteration_response.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
